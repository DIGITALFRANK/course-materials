\documentclass{beamer}

\usepackage{mjclectureslides}

\definecolor{Dblue}{rgb}{.255,.41,.884}

\title[Integration]
{Introduction to Analysis: \\ Integration}
%\author[Prof. Michael Carlisle]{Prof. Michael Carlisle} 
%\institute{Baruch College, CUNY}
%\date{Fall 2017}
\date{}

\begin{document}

\frame{\titlepage}


\frame{ \frametitle{A Very Brief History of Integration}

\begin{itemize}
\item Archimedes (3rd Century BCE): method of exhaustion
\item Isaac Newton (1642-1727) vs Gottfried Leibniz (1646-1716): physics, philosophy, religion
\item[$\star$] Bernhard Riemann (1826-1866): differential geometry, metrics, proto-quantum mechanics
\item[$\star$] Thomas Stieltjes (1856-1894): analytic theory, continued fractions
\item Henri Lebesgue (1875-1941): measure theory
\end{itemize}

}

% defn: partition of $[a,b]$, refinement
\frame{ \frametitle{Partition of the interval $[a,b]$, Refinement of a partition}

Let $[a,b]$ be an interval in $\R$. 

\vspace{5mm}

A \textbf{partition} $P$ of $[a,b]$ is a finite set of points 
\[ P = \{x_0, x_1, ..., x_n\} \subseteq [a,b] \] 
such that 
\[ a = x_0 < x_1 < \cdots < x_n = b. \]

\vspace{3mm}

If $P$ and $Q$ are partitions of $[a,b]$ and $P \subseteq Q$, then $Q$ is called a \textbf{refinement} of $P$. 

}


\frame{ \frametitle{Partition of the interval $[a,b]$, Refinement of a partition}

For a partition $P = \{x_0, x_1, ..., x_n\}$, define 
\[ \Delta x_i(P) = x_{i} - x_{i-1}, \,\, i=1, 2, ..., n. \]

\vspace{5mm}

These are the distances between consecutive points in the partition. 

\vspace{3mm}

We will abbreviate the notation to $\Delta x_i$ if context allows.

\vspace{5mm}

If $Q$ is a refinement of $P$, then $Q$ not only has more $\Delta x_i$ than $P$, but they are smaller as well. 

}


% max, min (sup, inf) functionals
\frame{ \frametitle{max and min (sup and inf), upper and lower sums}

Let $f:[a,b] \to \R$ be bounded, and $P$ a partition on $[a,b]$. Define 
\begin{align*} 
M_i(f) & = \sup \{ f(x): \,\, x \in [x_{i-1},x_i]\}, \\
m_i(f) & = \inf \{ f(x): \,\, x \in [x_{i-1},x_i]\}. 
\end{align*}
We will abbreviate the notation to $M_i$ and $m_i$ if context allows.

\vspace{5mm}

Define the \textbf{upper} and \textbf{lower Darboux sums} of $f$ with respect to $P$ by 
\begin{align*} 
U(P, f) & = \sum_{i=1}^n M_i(f) \Delta x_i(P), \\
L(P, f) & = \sum_{i=1}^n m_i(f) \Delta x_i(P).
\end{align*}


}


% upper integral U, lower integral L
\frame{ \frametitle{Upper, lower integrals; Riemann integral}

$f$ bounded implies $\exists m, M \in \R$, $-\infty < m \leq M < \infty$ such that 
\[ m(b-a) \leq L(P, f) \leq U(P, f) \leq M(b-a). \]

\vspace{5mm}

Define the \textbf{upper} and \textbf{lower integrals} of $f$ on $[a,b]$ by 
\begin{align*} 
U([a,b], f) & = \inf \{ U(P, f): \,\, P \text{ is a partition of } [a,b]\}, \\
L([a,b], f) & = \sup \{ L(P, f): \,\, P \text{ is a partition of } [a,b]\}. 
\end{align*}

}


\frame{ \frametitle{Upper, lower integrals; Riemann integral}

If 
\[ -\infty < L([a,b], f) = U([a,b], f) < \infty, \] 

then we say $f$ is \textbf{Riemann integrable} on $[a,b]$, and that the common value is the \textbf{Riemann integral} of $f$ on $[a,b]$, denoted 
\[ \int_a^b f, \,\, \text{ or } \int_a^b f(x) dx. \]

}


% defn: Riemann integrable, (proper) Riemann integral
\frame{ \frametitle{Riemann-Stieltjes integral}

To generalize, consider using a difference of another function $g$ that is monotone on $[a,b]$, For the differences 
\[ \Delta_g x_i = g(x_i)-g(x_{i-1}), \]

\vspace{3mm}

define the upper and lower sums of $f$ with respect to $P$ and $g$ by 
\begin{align*} 
U(P,f,g) & = \sum_{i=1}^n M_i(f) \Delta_g x_i, \\
L(P,f,g) & = \sum_{i=1}^n m_i(f) \Delta_g x_i.
\end{align*}

}

% eg
\frame{ \frametitle{Riemann-Stieltjes integral}

Similarly, define the upper and lower integrals by 
\begin{align*} 
U([a,b], f, g) & = \inf \{ U(P,f,g): \,\, P \text{ is a partition of } [a,b]\}, \\
L([a,b], f, g) & = \sup \{ L(P,f,g): \,\, P \text{ is a partition of } [a,b]\}.
\end{align*}

\vspace{5mm}

If $U([a,b], f,g) = L([a,b], f,g)$, then we call the common value the \textbf{Riemann-Stieltjes integral} (or \textbf{Stieltjes integral}) of $f$ with respect to $g$ on $[a,b]$, denoted 
\[ \int_a^b f \, dg, \,\, \text{ or } \int_a^b f(x) dg(x). \]

}


\frame{ \frametitle{Riemann-Stieltjes integral}

If $g$ is absolutely continuous on $[a,b]$, then the differential of $g$ is 
\[ dg(x) = g'(x) dx \]

\vspace{3mm}

and the Stieltjes integral can be rewritten as 
\[ \int_a^b f(x) dg(x) = \int_a^b f(x) g'(x) dx, \]

\vspace{3mm}

a form which has uses in probability theory and integration by parts (which we will see shortly). 

}



% thm: f bdd on [a,b] implies refinements of P order L, U
\frame{ \frametitle{$f$ bounded $\implies$ integral refinements are monotone}

\begin{thm}
Let $f$ be a bounded function on $[a,b]$. 

\vspace{5mm}

If $P$ and $Q$ are partitions of $[a,b]$ and $Q$ is a refinement of $P$, then 
\[ L(P,f) \leq L(Q, f) \leq U(Q, f) \leq U(P, f). \]
\end{thm}

\pf $L(Q, f) \leq U(Q, f)$ is immediate. 

\vspace{5mm}

We will show 
\[ U(Q, f) \leq U(P, f), \]
and note that a similar argument will result in 
\[ L(P, f) \leq L(Q, f). \]

}


\frame{ \frametitle{$f$ bounded $\implies$ integral refinements are monotone}


Suppose that $P = \{x_0, x_1, ..., x_n\}$. Pick $k \in \{1, 2, ..., n\}$. Then 
\[ \exists x^* \in (x_{k-1}, x_k): \,\, x^* \in Q \setminus P. \]

\vspace{3mm}

Let 
\[ P^* =  \{x_0, x_1, ..., x_{k-1}, x^*, x_k, ..., x_n\}. \]

\vspace{3mm}

Set 
\[ t_1 =  \sup \{ f(x): \,\, x \in [x_{k-1},x^*]\}, \,\, t_2 = \sup \{ f(x): \,\, x \in [x^*,x_k]\}. \] 

}


\frame{ \frametitle{$f$ bounded $\implies$ integral refinements are monotone}

Then, since $M_k \geq t_1$ and $M_k \geq t_2$, we have 
\begin{align*} 
U(P, f) & = \sum_{i=1}^{n} M_i \Delta x_i \\
 & \geq \sum_{i=1}^{k-1} M_i \Delta x_i + M_k (x^* - x_{k-1}) + M_k (x_k - x^*) + \sum_{i=k+1}^{n} M_i \Delta x_i \\
 & \geq \sum_{i=1}^{k-1} M_i \Delta x_i + t_1 (x^* - x_{k-1}) + t_2 (x_k - x^*) + \sum_{i=k+1}^{n} M_i \Delta x_i \\
  & = U(P^*, f). 
\end{align*}
Note that $U(Q, f)$ is achieved by repeating this process until all of $Q$'s extra points above $P$ are inserted. \,\, $\blacksquare$

}


\frame{ \frametitle{Lower, upper integrals of a bounded function}

Limiting the inequality from this theorem, 
\[ L(P,f) \leq L(Q,f) \leq U(Q,f) \leq U(P,f), \]
as refinements get finer and finer, results in 

\vspace{5mm}

\begin{thm}
Let $f$ be a bounded function on $[a,b]$. Then 
\[ L([a,b], f) \leq U([a,b], f). \]
\end{thm}

We can see various examples of this limiting by using specific sequences of refinements. For example, let 
\[ P_n = \left\{a, a+\frac{1}{n}, a+\frac{2}{n}, ..., b-\frac{1}{n}, b \right\} \]
and send $n \to \infty$. 

}



% thm: f bdd on [a,b], Then f integrable iff partition differences shrink.
\frame{ \frametitle{Bounded functions with shrinking $U-L$ gap are integrable}

For $f$ to be integrable, as refinements increase in cardinality, 
\[ U(P,f) - L(P,f) \to 0. \]

\vspace{5mm}

This is a theorem, that looks similar to our notions of limit existence (because that is, in fact, what it is). 

}


\frame{ \frametitle{Bounded functions with shrinking $U-L$ gap are integrable}

\begin{thm}
Let $f$ be a bounded function on $[a,b]$. 

\vspace{5mm}

Then $f$ is integrable $\iff$ for each $\ve > 0$, $\exists$ a partition $P$ of $[a,b]$:
\[ U(P,f) - L(P,f) < \ve. \]
\end{thm}

}


% thm: f bdd on [a,b], Then f integrable iff partition differences shrink.
\frame{ \frametitle{Bounded functions with shrinking $U-L$ gap are integrable}

\pf 

\vspace{3mm}

( $\Longleftarrow$ ) First, for arbitrary $\ve > 0$, suppose such a $P$ exists that 
\[ U(P,f) - L(P,f) < \ve. \]
Then, since $\ve$ was arbitrary, we have 
\[ U([a,b],f) \leq U(P,f) < L(P,f) + \ve \leq L([a,b],f) + \ve, \]
and so must have $U([a,b],f) \leq L([a,b],f)$. 

\vspace{5mm}

But by the previous theorem, $L([a,b],f) \leq U([a,b],f)$. Therefore, 
\[ L([a,b],f) = U([a,b],f). \]

}


\frame{ \frametitle{Bounded functions with shrinking $U-L$ gap are integrable}

($\implies$) Suppose $\exists \ve > 0$ such that, for any partition $P$, we have 
\[ U(P,f) - L(P,f) \geq \ve. \]

\vspace{3mm}

Then, for any partition $P$, 
\[ U(P,f) \geq L(P,f) + \ve, \]

\vspace{3mm}

yielding the limiting inequality 
\[ U([a,b],f) \geq L([a,b],f) + \ve.\]

\vspace{3mm}

Therefore, since $U([a,b],f) \neq L([a,b],f)$, $f$ is not integrable.  \,\, $\blacksquare$

}


\frame{ \frametitle{Integration of a constant function is area of a rectangle}

Our first computational result tells us the value of the Riemann integral of a constant function.

\begin{thm}
If $f$ is the constant function $f(x) = c$ on $[a,b]$, then 
\[  \int_a^b f(x) \, dx = c(b-a). \]
\end{thm}

}


\frame{ \frametitle{Integration of a constant function is area of a rectangle}

\pf For any partition $P$ of $[a,b]$, 
\[ M_i(f) = m_i(f) = c. \]
Thus, 
\[ U(P, f) = L(P, f) = \sum_{i=1}^n c \Delta x_{i} = c \sum_{i=1}^n \Delta x_{i} = c(b-a). \,\, \blacksquare \]

\vspace{3mm}

This value of the definite integral 
\[  \int_a^b f(x) \, dx = c(b-a). \]
is the area\footnote{This is called \emph{signed} area: if $c < 0$ the graphed area is ``below the $x$-axis".} of the rectangle of height $c$ with base width $b-a$.

}


% thm: f monotone on [a,b] implies f integ
\frame{ \frametitle{Monotone functions are integrable}

Now we will classify some types of functions as integrable. 

\vspace{5mm}

\begin{thm}
Let $f$ be a monotone function on $[a,b]$. Then $f$ is integrable. 
\end{thm}

\vspace{5mm}

\pf WLOG let $f$ be an increasing function. 

\vspace{5mm}

Clearly, $f$ is bounded on $[a,b]$, and in fact 
\[ m = f(a) \leq f(b) = M. \]

}


\frame{ \frametitle{Monotone functions are integrable}

If $P = \{a = x_0, x_1, ..., x_n = b\}$ is a partition of $[a,b]$, then 
\[ m_i = f(x_{i-1}) \text{ and } M_i = f(x_i) \text{ for } i=1,2,...,n. \]

\vspace{3mm}

Since $f$ is bounded, then by the Archimedean property, 
\begin{align*} 
\forall \ve > 0, \,\, \exists k =k(\ve) > 0: \,\, \forall i = 1, 2, ..., n, \,\, k(M-m) < \ve. 
\end{align*}

}


\frame{ \frametitle{Monotone functions are integrable}

Thus, if we choose a partition $P$ such that $\Delta x_i \leq k$ for all $i$, 
\begin{align*} 
U(P,f) - L(P,f) & = \sum_{i=1}^n [f(x_i) - f(x_{i-1})] \Delta x_i \\
 & \leq k \sum_{i=1}^n [f(x_i) - f(x_{i-1})] \\
 & = k [f(b) - f(a)] = k(M-m) < \ve. 
\end{align*}

\vspace{5mm}

Since $\ve > 0$ was arbitrary, this means that by our previous theorem, $U([a,b],f) = L([a,b],f)$, and so $f$ is integrable. \,\, $\blacksquare$

}


% thm: f cont implies f integrable
\frame{ \frametitle{Continuous functions are integrable}

\begin{thm}
Let $f$ be a continuous function on $[a,b]$. Then $f$ is integrable. 
\end{thm}

\vspace{5mm}

\pf Suppose $f$ is continuous on $[a,b]$. 

\vspace{5mm}

Since $[a,b]$ is compact, $f$ is uniformly continuous on $[a,b]$. 

\vspace{5mm}

Thus, for any $\ve > 0$, $\exists \delta > 0$ such that, if $x, y \in [a,b]$, 
\[ |x-y| < \delta \implies |f(x) - f(y)| < \frac{\ve}{b-a}. \]

}


\frame{ \frametitle{Continuous functions are integrable}

Now select:
\begin{itemize}
\item a partition $P$ such that $\Delta x_{i} < \delta$ for every $i$, 
\item $s_i, t_i \in [x_{i-1}, x_i]$ for each $i$ such that 
\[ m_i = f(s_i) \text{ and } M_i = f(t_i). \]
\end{itemize}

\vspace{5mm}

Then
\[ U(P,f) - L(P,f) = \sum_{i=1}^n [M_{i} - m_{i}] \Delta x_{i} < \frac{\ve}{b-a} \sum_{i=1}^n \Delta x_{i} = \ve, \]
and so $f$ is integrable. \,\, $\blacksquare$
}



% eg: simple results via contrapositives: 
% f not integ implies f not cont implies f not diff; f not integ implies f not monotone
\frame{ \frametitle{Non-integrable functions are not continuous or monotone}

The contrapositives of the previous two theorems are logically equivalent to those theorems. Therefore,

\vspace{3mm}

\begin{cor}
If $f$ is not integrable on $[a,b]$, then $f$ is not monotone on $[a,b]$. 
\end{cor}

\begin{cor}
If $f$ is not integrable on $[a,b]$, then $f$ is not continuous on $[a,b]$. 
\end{cor}

\vspace{5mm}

These do \emph{not}, however, imply that 
\begin{itemize}
\item no discontinuous functions are integrable \\(many are, such as simple functions), nor that 
\item no non-monotone functions are integrable \\(there are, for example, non-monotone continuous functions). 
\end{itemize}

}


\frame{ \frametitle{Integration is a linear operation}

\begin{thm}
Integration on $[a,b]$ is a \emph{linear operation}.

 \vspace{3mm}
 
More specifically, if $f$ and $g$ are integrable functions on $[a,b]$ and $c_1, c_2 \in \R$, then the function $c_1 f + c_2 g$ is also integrable on $[a,b]$, and 
\[ \int_a^b (c_1 f + c_2 g) = c_1 \int_a^b f + c_2 \int_a^b g. \]
\end{thm}

}


\frame{ \frametitle{Integration is a linear operation}

\pf We will prove this theorem in two pieces: 

\vspace{3mm}

\begin{itemize}
\item For any $c \in \R$, $cf$ is integrable, and 
\[ \int_a^b c f = c \int_a^b f. \]
\item $f+g$ is integrable, and 
\[ \int_a^b (f + g) = \int_a^b f + \int_a^b g. \]
\end{itemize}

}


\frame{ \frametitle{Integration is a linear operation}

\begin{itemize}
\item For any $c > 0$ and partition $P$, it is clear that 
\[ U(P, c f) = c U(P,f), \,\, L(P, c f) = c L(P,f). \]
The result follows since $f$ is integrable on $[a,b]$: 
\[ U(P,cf) - L(P,cf) = c( U(P, f) - L(P, f) ). \]

\vspace{3mm}

For $c < 0$, 
\[ U(P, c f) = c L(P,f), \,\, L(P, c f) = c U(P,f) \]
and the result still follows.
\end{itemize}

}


\frame{ \frametitle{Integration is a linear operation}

\begin{itemize}
\item By properties of $\max$, 
\[ U(P, f+g) \leq U(P,f) + U(P, g), \]
and by properties of $\min$, 
\[ L(P, f+g) \geq L(P,f) + L(P, g). \]
\end{itemize}
Thus, if $f$ and $g$ are integrable on $[a,b]$, 
\[ 0 \leq U(P,f+g) - L(P,f+g) \leq U(P,f) - L(P,f) + U(P,g) - L(P,g), \]
and the result follows. \,\, $\blacksquare$

}


\frame{ \frametitle{Mean Value Theorem for Integrals}

\begin{thm}
\textbf{Mean Value Theorem (integrals)}: 

\vspace{5mm}

If $f:[a,b] \to \R$ is continuous, then $\exists c \in [a,b]$ such that 
\[ \frac{1}{b-a} \int_a^b f(x) dx = f(c). \]
\end{thm}

}


\frame{ \frametitle{Mean Value Theorem for Integrals}

\pf $f$ is continuous on the closed interval $[a,b]$, so by the EVT $f$ attains its maximum $M$ and minimum $m$ on $[a,b]$. Thus, 
\[ \forall x \in [a,b], \,\, m \leq f(x) \leq M. \]

Hence, for any approximating sum of the Riemann integral 
\[ \int_a^b f(x) dx, \]

we have, for whatever choices of $x_i$ and $x_i'$, and lower and upper sums $s_n$ and $S_n$, 
\[ m \sum_{i=1}^n \Delta x_i \leq s_n \leq \sum_{i=1}^n f(x_i') \Delta x_i \leq S_n \leq M\sum_{i=1}^n \Delta x_i. \]

}


\frame{ \frametitle{Mean Value Theorem for Integrals}

But, as we have seen before, 
\[ \sum_{i=1}^n \Delta x_i = b-a. \]

\vspace{3mm}

Therefore, we have 
\[ m (b-a) \leq \sum_{i=1}^n f(x_i') \Delta x_i \leq M(b-a) \]

for any approximating sum. 

}


\frame{ \frametitle{Mean Value Theorem for Integrals}

Taking the limit, we get the same bounds on the Riemann integral: 
\[ m (b-a) \leq \int_a^b f(x) dx \leq M(b-a) \implies m \leq \frac{1}{b-a}\int_a^b f(x) dx \leq M. \]

Set
\[ \mu = \frac{1}{b-a}\int_a^b f(x) dx \] 

as the average (mean) value of $f$ over $[a,b]$.

\vspace{5mm}

Since $m \leq \mu \leq M$, by the IVT we know 
\[ \exists c \in [a,b]: \,\, f(c) = \mu. \,\, \blacksquare \]

}


\frame{ \frametitle{Function Dominance (integrals)}

\begin{thm}
\textbf{Function Dominance (integrals)}: If 
\[ \forall x \in [a,b], \,\, f(x) \leq g(x), \]
and $f$ and $g$ are integrable on $[a,b]$, then 
\[ \int_a^b f(x) dx \leq \int_a^b g(x) dx. \] 
\end{thm}

}


\frame{ \frametitle{Function Dominance (integrals)}

\pf If $f$ and $g$ are integrable, then so is $g-f$, and 
\[ g(x) - f(x) \geq 0 \text{ for all } x \in [a,b]. \]

\vspace{3mm}

Thus, for any partition $P$ of $[a,b]$, 
\[ 0 \leq L(P, g-f) \leq U(P, g-f), \,\, \text{ and } L(P, 0) = U(P, 0) = 0. \]

\vspace{3mm}

Hence, 
\[ 0 = \int_a^b 0 \, dx \leq \int_a^b (g(x)-f(x)) \, dx = \int_a^b g(x) \, dx - \int_a^b f(x) \, dx. \,\, \blacksquare \] 

}


\frame{ \frametitle{Integrals sum across consecutive intervals}

\begin{thm}
If $f$ is integrable on $[a,c]$ and $[c,b]$, then $f$ is integrable on $[a,b]$ and 
\[ \int_a^b f(x) dx = \int_a^c f(x) dx + \int_c^b f(x) dx. \] 
\end{thm}

\pf Let $\ve > 0$. Then $\exists$ partitions $P_1$ of $[a,c]$, $P_2$ of $[c,b]$: 
\[ U(P_1,f) - L(P_1,f) < \frac{\ve}{2}, \,\, U(P_2,f) - L(P_2,f) < \frac{\ve}{2}. \]
Then $P_1 \cup P_2$ is a partition of $[a,b]$ and 
\begin{align*} 
U(P,f) - L(P,f) & = U(P_1,f) + U(P_2,f) - L(P_1,f) - L(P_2,f) < \ve. 
\end{align*}
Thus, $f$ is integrable on $[a,b]$. The equality follows. \,\, $\blacksquare$
}


\frame{ \frametitle{Composition of integrable functions is integrable}

Although we will not prove it here, we will need the following theorem shortly.

\vspace{5mm}

\begin{thm}
If $f$ is integrable on $[a,b]$ and $g$ is continuous on $[c,d]$, where $f([a,b]) \subseteq [c,d]$, then $g \circ f$ is integrable on $[a,b]$.
\end{thm}

}


\frame{ \frametitle{Triangle inequality (integral version)}

\begin{thm}
Let $f$ be integrable on $[a,b]$. Then $|f|$ is integrable on $[a,b]$ and 
\[ \left| \int_a^b f\right| \leq \int_a^b |f|. \]
\end{thm}

\vspace{5mm}

\pf By the previous theorem, since $g(x) = |x|$ is continuous on $\R$, we have that $g \circ f(x) = |f(x)|$ is integrable on $[a,b]$. 

\vspace{5mm}

By dominance, since $-|f(x)| \leq f(x) \leq |f(x)|$ for all $x \in [a,b]$,  
\[  -\int_a^b |f| \leq \int_a^b f \leq \int_a^b |f| \implies \left| \int_a^b f\right| \leq \int_a^b |f|. \,\,\,\, \blacksquare \]


}



% first, notation: Let $a < b$. then $\int_b^a f = -\int_a^b f$, and $\int_a^a f = 0$. 
\frame{ \frametitle{Some interval notation for integrals}

Recall some notation for integrals: over the interval $[a,b]$, 
\begin{align*}
\int_b^a f & = -\int_a^b f \\
 & \\
\int_a^a f & = 0.
\end{align*}

}


\frame{ \frametitle{Definite Integrals: Variable of Integration}

The \textbf{variable of integration}, or the \textbf{``dummy variable''}, of an integral, is the variable used \emph{inside} the integration\footnote{This is not the same usage as ``dummy variable'' as an indicator function in statistics.}. 

\vspace{3mm}

For example, in the notation 
\[ \int_a^b f(x) \, dx, \]
the variable $x$ is the dummy variable, and can be replaced with a different, unused letter\footnote{This is why the dummy-less notation $\int_a^b f$ is acceptable.}.

\vspace{3mm}

We will refer to Riemann integrals on a compact interval $[a,b]$ as \textbf{definite integrals}. 

}


\frame{ \frametitle{Definite Integrals: Limits of Integration}

For definite integrals, if the \textbf{limits of integration} (endpoints $a, b$ of the interval one integrates over) are fixed constants, then 
\[ \int_a^b f(x) dx = \int_a^b f(t) dt = \int_a^b f(v) dv = \int_a^b f(u) du = ... \]

all mean the same value. 

\vspace{3mm} 

However, when a limit of integration (typically the upper limit) is a \emph{variable}, we must avoid a notation issue. 

}


\frame{ \frametitle{Variable Limits of Integration}

If $x$ is intended as a variable limit of integration, the expression 
\[ \int_a^x f(x) dx \]
doesn't make sense, as $x$ cannot simultaneously be used as a limit of integration and the variable of integration.

}


\frame{ \frametitle{Variable Limits of Integration}

Suppose we have a function defined by a variable limit of integration. If $f$ is integrable on $[a,b]$, let, for $a \leq x \leq b$, 
\[ F(x) = \int_a^x f(t) dt \]
be the definite integral of $f$ on the variable compact interval $[a,x]$. 

\vspace{5mm}

This notation is acceptable, as long as the dummy variable \\(here, $t$) and the limit of integration / function variable (here, $x$) are different symbols.

}



\frame{ \frametitle{The Fundamental Theorems of Calculus}

With this notation, we now state and prove the two 

\vspace{3mm}

\begin{center}
\textbf{Fundamental Theorems of Calculus} (FTC), 
\end{center}

\vspace{3mm}

which relate differentiation and integration. 

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}

\begin{thm} 
\textbf{(Fundamental Theorem of Calculus I)}: 

\vspace{3mm}

Suppose $f$ is integrable on $[a,b]$. For $x \in [a,b]$, define 
\[ F(x) = \int_a^x f(t) dt. \]

Then $F$ is uniformly continuous on $[a,b]$. 

\vspace{5mm}

Furthermore, if $f$ is continuous on $[a,b]$, 
then $F$ is differentiable on $(a,b)$ and 
\[ \forall c \in (a,b), \,\, F'(c) = f(c). \]
\end{thm}

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}

\pf First, we show that $F$ is uniformly continuous on $[a,b]$.

\vspace{5mm}

$f$ is integrable on $[a,b]$ $\implies$ $f$ is bounded on $[a,b]$, i.e. 
\[ \exists B > 0: \,\, \forall x \in [a,b], \,\, |f(x)| \leq B. \]

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}

Let $\ve > 0$. Then $\exists \delta = \frac{\ve}{B} > 0$, such that if $x,y \in [a,b]$ and $x < y$, 
\begin{align*}
|y - x| < \delta \\
\implies |F(y) - F(x)| & = \bigg| \int_a^y f(t) dt - \int_a^x f(t) dt \bigg| \\
 & = \bigg| \int_x^y f(t) dt \bigg| \\
 & \leq \int_x^y |f(t)| dt \\
 & \leq \int_x^y B \, dt \\
 & = B(y-x) < \ve.
\end{align*}

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}

Each inequality uses a separate theorem: 
\begin{align*} 
& f \text{ integrable on } [a,c], [c,b] & \implies & \int_a^b f = \int_a^c f + \int_c^b f, \\
& f \text{ integrable on } [a,b] & \implies & \left| \int_a^b f\right| \leq \int_a^b |f|, \\
& f, g \text{ integrable on } [a,b] \text{ and } f(x) \leq g(x) & \implies & \int_a^b f \leq \int_a^b g, \\
& \text{ and } f \text{ constant on } [a,b], \, f(x) = c & \implies & \int_a^b f = c(b-a). 
\end{align*}

\vspace{3mm}

Thus, since $\delta = \frac{\ve}{B}$ does not depend on $x$ and $y$, $F$ is uniformly continuous on $[a,b]$.

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}

Next, suppose that $f$ is continuous at a fixed $c \in [a,b]$. 

\vspace{3mm}

If $\ve > 0$, 
\[ \exists \delta > 0: \,\, t \in [a,b], \,\, |t - c| < \delta \implies |f(t) - f(c)| < \ve. \]

\vspace{3mm}

$f(c)$ is a constant, so we can write $f(c)$ as an integral: for $x \neq c$, 
\[ f(c) = \frac{1}{x-c} \int_c^x f(c) \, dt. \]

\vspace{3mm}

Note that it does not matter if $x < c$ or $x > c$ here, only that $x \in [a,b]$ and that $x \neq c$. 

}


\frame{ \frametitle{The Derivative of an Integral: FTC I}
 
Then, if $x \in [a,b]$ such that $0 < |x-c| < \delta$, 

\begin{align*}
\bigg| D_F(x,c) - f(c) \bigg| & = \bigg| \frac{F(x) - F(c)}{x-c} - \frac{\int_c^x f(c) \, dt}{x-c} \bigg| \\
 & = \bigg| \frac{\int_a^x f(t) \, dt - \int_a^c f(t) \, dt}{x-c} - \frac{\int_c^x f(c) \, dt}{x-c} \bigg| \\
 & = \bigg| \frac{\int_c^x f(t) \, dt}{x-c} - \frac{\int_c^x f(c) \, dt}{x-c} \bigg| \\
 & \leq \frac{1}{|x-c|} \int_c^x |f(t) - f(c)| \, dt \\
 & < \frac{1}{|x-c|} \ve |x-c| = \ve. \\
 & \\
\therefore \,\, F'(c) = \lim_{x \to c} D_F(x,c) & = f(c). \,\,\,\, \blacksquare
\end{align*}

}


\frame{ \frametitle{Antiderivatives (Indefinite Integrals)}
 
A differentiable function $F$ on an interval $[a,b]$ such that 
\[ \forall x \in (a,b), \,\, F'(x) = f(x) \]
for a function $f$ defined on $[a,b]$ is called an \textbf{antiderivative}, or \textbf{indefinite integral}, of $f$. 

\vspace{5mm}

FTC I establishes the existence of antiderivatives. 

\vspace{5mm}

However, antiderivatives are not \emph{unique} to a given function $f$.

}


\frame{ \frametitle{Antiderivatives are Not Unique}
 
If $F$ is an antiderivative of $f$, and $G(x) = F(x) + C$ for some constant $C \in \R$, then 
\[ G'(x) = \frac{d}{dx}( F(x) + C ) = f(x) \]
and so $G$ is also an antiderivative of $f$.

\vspace{5mm}

We typically refer to ``the antiderivative" $F$ of a function $f$ as a \emph{family} of functions of the form 
\[ F(x) + C, \]
where we refer to $C$ as the \textbf{constant of integration}.

}




\frame{ \frametitle{The Inverse of Differentiation (Antiderivatives)}

Consider a \emph{first-order linear differential equation}, of the form 
\[ \frac{dy}{dx} = f(x). \]

We are to compute the antiderivative $y$ via separation of variables and integration using differentials. First, write 
\[ dy = f(x) \, dx \]

considering $dy$ and $dx$ as \emph{differentials}, denoting changes in $y$ and $x$. 

}


\frame{ \frametitle{The Inverse of Differentiation (Antiderivatives)}

We use the integral sign $\int$ without limits of integration to commit the inverse operation of differentiation on differentials.

\vspace{5mm}

Letting 
 \[ y = \int dy, \]
 
 we say 
\[ y = \int dy = \int f(x) \, dx = F(x) + C. \]

\vspace{5mm}

In practice, this requires some skill in pattern recognition to notice how to apply differentiation rules ``in reverse''.

}


\frame{ \frametitle{The Inverse of Differentiation (Antiderivatives)}

An antiderivative $F$ of the function 
\[ y = f(x) \] 

is a \textbf{general solution} to the differential equation
\[ \frac{dy}{dx} = f(x). \]

\vspace{3mm}

With an initial or boundary condition, we get a \textbf{particular solution} of one function, rather than a ``$+ C$'' general solution family.

}


\frame{ \frametitle{Substitution on Upper Limit of Integration}

\begin{cor}
\textbf{(Chain Rule for Integrals: Limits of Integration)} \\
Let $f$ be continuous on $[a,b]$ and $g$ differentiable on $[c,d]$, \\
where $g([c,d]) \subseteq [a,b]$. 

\vspace{3mm}

For $x \in [c,d]$, define 
\[ F(x) = \int_a^{g(x)} f(t) \, dt. \]
Then $F$ is differentiable on $[c,d]$ and 
\[ F'(x) = (f \circ g)(x) \cdot g'(x). \]
\end{cor}

}


\frame{ \frametitle{Substitution on Upper Limit of Integration}

\pf Define 
\[ G(x) = \int_a^x f(t) \, dt, \] 
so that 
\[ F(x) = G \circ g(x) = \int_a^{g(x)} f(t) \, dt \]
on $[c,d]$. Apply the Chain Rule for derivatives and the FTC I. \,\, $\blacksquare$

}


\frame{ \frametitle{The Integral of a Derivative: FTC II}

\begin{thm} 
\textbf{(Fundamental Theorem of Calculus II)}: 

\vspace{3mm}

Suppose $f$ is integrable on $[a,b]$, with antiderivative $F$. Then 
\[ \int_a^b f(x) dx = F(b) - F(a). \]
\end{thm}

\vspace{5mm}

When computing definite integrals, we often use the notation 
\[ [F(x)|_a^b = F(b) - F(a) \]
to display the use of the antiderivative $F$ as a function.

}


\frame{ \frametitle{The Integral of a Derivative: FTC II}

\pf Let 
\[ H(x) = \int_a^x f(t) dt. \]

By FTC I, $H'(x) = f(x)$. Thus, $G$ defined by 
\[ G(x) = F(x) - H(x) = F(x) - \int_a^x f(t) dt \]

is a constant, since its derivative is 
\[ G'(x) = f(x) - H'(x) = 0. \]

}


\frame{ \frametitle{The Integral of a Derivative: FTC II}

Evaluating $G$ at the endpoints $a$ and $b$, we have 
\begin{align*} 
G(a) & = f(a) - H(a) = f(a) \,\,\,\, \text{ since } H(a) = 0 \\
G(b) & = f(b) - H(b) = f(b) - \int_a^b f'(t) dt \\
G(b) & = G(a) \,\,\,\, \text{ since } G \text{ is constant. } \\
\text{Thus, } f(a) & = f(b) - \int_a^b f'(t) dt. \\
\therefore \,\,\,\, & \int_a^b f'(t) dt = f(b) - f(a). \,\, \blacksquare
\end{align*}

}


\frame{ \frametitle{Chain Rule for Indefinite Integrals: Substitution}

\begin{thm} 
\textbf{($u$-substitution, i.e. Chain Rule for Indefinite Integrals)}: \\
Suppose $f$ is continuous with antiderivative $F$. \\
Suppose $g$ is differentiable and $g'$ is continuous.

\vspace{5mm}

Then the substitution 
\[ u = g(x), \,\, du = g'(x) \, dx \]
can be used to simplify integration of the form: 
\begin{align*} 
\int f(g(x)) g'(x) dx & = \int f(u) du.
\end{align*}
\end{thm}

}


\frame{ \frametitle{Chain Rule for Definite Integrals: Substitution}

\begin{thm} 
\textbf{($u$-substitution, i.e. Chain Rule for Definite Integrals)}: \\
Suppose $f$ is continuous on $[a,b]$ with antiderivative $F$. \\
Suppose $g$ is differentiable and $g'$ is continuous on $[\alpha, \beta]$, such that 
\[ g(\alpha) = a \leq g(t) \leq b = g(\beta). \]

Then the substitution 
\[ u = g(x), \,\, du = g'(x) \, dx \]
can be used to simplify integration of the form: 
\begin{align*} 
\int_{\alpha}^{\beta} f(g(x)) g'(x) dx & = \int_a^b f(u) du = F(b) - F(a).
\end{align*}
\end{thm}

}


\frame{ \frametitle{Mean Value Theorem for Integrals}

\begin{thm}
\textbf{(Mean Value Theorem, Integrals)}: \\
If $f:[a,b] \to \R$ is continuous, then $\exists c \in (a,b)$ such that 
\[ \frac{1}{b-a} \int_a^b f(t) dt = f(c). \]
\end{thm}

\vspace{3mm}

\pf An antiderivative $F$ of $f$ is (uniformly) continuous on $[a,b]$, and so by the MVT for derivatives, $\exists c \in (a,b)$ such that
\[ \frac{F(b) - F(a)}{b-a} = F'(c). \]
Due to FTC II,  
\[ F'(c) = \frac{1}{b-a} \int_a^b f(t) dt = f(c). \,\,\,\, \blacksquare \]

}


\frame{ \frametitle{Integration By Parts}

\begin{thm} \textbf{(Integration by Parts, Indefinite Integrals)} \\
Suppose $f$ and $g$ are differentiable and $f'$ and $g'$ are integrable. Then 
\[ \int f(x) g'(x) dx = f(x) g(x) - \int f'(x) g(x) dx. \]
\end{thm}

\pf Use the product rule for derivatives to show, up to a $+C$,  
\begin{align*} 
\int [f(x) g'(x) + f'(x) g(x)] dx  & = \int [f(x)g(x)]' dx. \,\, \blacksquare
\end{align*}

}


\frame{ \frametitle{Integration By Parts}

\begin{thm} \textbf{(Integration by Parts, Definite Integrals)} \\
Suppose $f$ and $g$ are differentiable on $[a,b]$, and $f'$ and $g'$ are integrable on $[a,b]$. Then 
\[ \int_a^b f(x) g'(x) dx = [f(x) g(x)|_a^b - \int_a^b f'(x) g(x) dx. \]
\end{thm}

\pf Combine the product rule for derivatives and FTC II for
\begin{align*} 
\int_a^b [f(x) g'(x) + f'(x) g(x)] dx  & = \int_a^b [f(x)g(x)]' dx \\
 & = f(b) g(b) - f(a) g(a). \,\,\,\, \blacksquare
\end{align*}

}


\frame{ \frametitle{Taylor's Theorem Remainder (integral form)}

Recall Taylor's Theorem, which generalizes the MVT for higher derivatives: 

\begin{thm} 
\textbf{(Taylor's Theorem)}: \\
Let $f \in C^{n+1}([a,b])$, and let $x_0 \in [a,b]$. Then, for each $x \in [a,b]$ with $x \neq x_0$, and $n \in \N$, $\exists c = c(n)$ between $x$ and $x_0$ such that 
\begin{align*} 
f(x) = f(x_0) & + f'(x_0) (x-x_0) + \frac{f''(x_0)}{2!}(x-x_0)^2 \\
 & + ... + \frac{f^{(n)}(x_0)}{n!} (x-x_0)^n + {\color{blue}\frac{f^{(n+1)}(c)}{(n+1)!} (x-x_0)^{n+1}}.  % + R_{n+1}, 
\end{align*}
\end{thm}

}


\frame{ \frametitle{Taylor's Theorem Remainder (integral form)}

We can now see that the remainder term 
\[ {\color{blue}R_{n+1}(x) = \frac{f^{(n+1)}(c)}{(n+1)!} (x-x_0)^{n+1}} \]
can be written as an integral without reference to the MVT's $c$, and the theorem can be restated: 

\begin{thm} 
\textbf{(Taylor's Theorem)}: \\
 Let $f \in C^{n+1}([a,b])$, and let $x_0 \in [a,b]$. Then, for each $x \in [a,b]$ with $x \neq x_0$, and for each $n \in \N$, 
\begin{align*} 
f(x) = f(x_0) & + f'(x_0) (x-x_0) + \frac{f''(x_0)}{2!}(x-x_0)^2 \\
 & + ... + \frac{f^{(n)}(x_0)}{n!} (x-x_0)^n + {\color{blue}\frac{1}{n!} \int_{x_0}^x f^{(n+1)}(t) (x-t)^{n} dt}.
\end{align*}
\end{thm}

}


% defn: improper integral on $(a,b]$...
\frame{ \frametitle{Improper Integral on $(a,b]$}

Let $f$ be defined on $(a,b]$ and integrable on $[c,b]$ for every $c \in (a, b]$. If 
\[ \lim_{c \to a+} \int_c^b f(x) dx \]
exists, then the \textbf{improper integral} of $f$ on $(a,b]$, is denoted by 
\[ \int_a^b f(x) dx. \]

}


\frame{ \frametitle{Improper Integral on $(a,b]$}

Certainly, if 
\[ \lim_{c \to a+} \int_c^b f(x) dx = L < \infty, \]
and $f$ is defined at $a$, then the improper integral and proper integral on $[a,b]$ match with value $L$, regardless of the value $f(a)$. 

\vspace{3mm}

In this case we say the improper integral \textbf{converges} to $L$. 

\vspace{5mm}

Otherwise, the improper integral \textbf{diverges}. (Similar for $[a,b)$.)

}


% improper integral on $[a,\infty)$
\frame{ \frametitle{Improper Integral on $[a,\infty)$}

If $f$ is defined on $[a,\infty)$, and integrable on $[a,c]$ for every $c > a$, then if 
\[ \lim_{c \to \infty} \int_a^c f(x) dx \]
exists, we call its value the \textbf{improper integral} on $[a,\infty)$, and denote it by 
\[  \int_a^{\infty} f(x) dx = \lim_{c \to \infty} \int_a^c f(x) dx.  \]
(We do similarly for $(-\infty, a]$.)

\vspace{5mm}


}


\frame{ \frametitle{Antiderivatives Without Closed Forms}

%What is meant by a ``closed-form'' solution is that the class of \emph{elementary functions}: f

Functions built out of algebraic functions (polynomials and roots), exponentials, logarithms,  trigonometric functions, and inverse trigonometric functions all have derivatives; the operation 
\[ f \mapsto f' \]
is \emph{closed} under these \emph{elementary functions}. However, 
\[ f \mapsto \int f \]
is \emph{not} closed under elementary functions. For example, the antiderivative (integral) of 
\[ f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \]
has no \emph{closed form} in terms of elementary functions.

}


\frame{ \frametitle{Antiderivatives Without Closed Forms}

That said, we can find \emph{infinite series} representations of such functions. For example, recall the power series representation of $e^x$: 
\[ e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!}. \]
While we consider $e^x$ to be an elementary function, we do not consider the power series representation as a ``closed form'' of $e^x$. 

\vspace{3mm}

\begin{defn}
A \textbf{closed form expression} is a mathematical expression that can be evaluated in a finite number of operations. 

\vspace{3mm}

These operations may be algebraic, trigonometric, exponential, or logarithmic, as these are accepted \textbf{elementary functions}. 
\end{defn}

\vspace{5mm}

%We will return to this notion at the end of the course.

}
% the key here, though, is that elementary functions are defined in terms of complex functions on a differential algebra. Exponentials are allowed from du = u da, and logs from du = da / a.
% THAT'S why trig functions and inverses are elementary: they're expressible as finite combinations of complex exponentials. 


%-------------



\end{document}
